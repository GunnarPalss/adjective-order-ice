{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "#Þessi klasi fékkst á þræðinum https://github.com/facebookresearch/fastText/pull/552\n",
    "#Þar sem Python Api bauð ekki upp á NN greiningu, þá er farinn þessi leið\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import fasttext\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from fasttext import load_model\n",
    "\n",
    "class FastTextNN:\n",
    "    \n",
    "    def __init__(self, ft_model, ft_matrix=None):\n",
    "        self.ft_model = ft_model        \n",
    "        self.ft_words = ft_model.get_words()\n",
    "        self.word_frequencies = dict(zip(*ft_model.get_words(include_freq=True)))\n",
    "        self.ft_matrix = ft_matrix\n",
    "        if self.ft_matrix is None:\n",
    "            self.ft_matrix = np.empty((len(self.ft_words), ft_model.get_dimension()))\n",
    "            for i, word in enumerate(self.ft_words):\n",
    "                self.ft_matrix[i,:] = ft_model.get_word_vector(word)\n",
    "    \n",
    "    def find_nearest_neighbor(self, query_word, vectors, n=10,  cossims=None):\n",
    "        \"\"\"\n",
    "        vectors is a 2d numpy array corresponding to the vectors you want to consider\n",
    "\n",
    "        cossims is a 1d numpy array of size len(vectors), which can be passed for efficiency\n",
    "        returns the index of the closest n matches to query within vectors and the cosine similarity (cosine the angle between the vectors)\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        query  = self.ft_model.get_word_vector(query_word)\n",
    "        if cossims is None:\n",
    "            cossims = np.matmul(vectors, query, out=cossims)\n",
    "\n",
    "        norms = np.sqrt((query**2).sum() * (vectors**2).sum(axis=1))\n",
    "        cossims = cossims/norms\n",
    "        if query_word in self.ft_words:\n",
    "            result_i = np.argpartition(-cossims, range(n+1))[1:n+1]\n",
    "        else:\n",
    "            result_i = np.argpartition(-cossims, range(n+1))[0:n]\n",
    "        return list(zip(result_i, cossims[result_i]))\n",
    "\n",
    "    def nearest_words(self, word, n=10, word_freq=None):\n",
    "        result = self.find_nearest_neighbor(word, self.ft_matrix, n=n)\n",
    "        if word_freq:\n",
    "            return [(self.ft_words[r\n",
    "            [0]], round(r[1],3)) for r in result if self.word_frequencies[self.ft_words[r[0]]] >= word_freq]\n",
    "        else:\n",
    "            return [(self.ft_words[r[0]], round(r[1],3)) for r in result]\n",
    "\n",
    "model = load_model('data/rmh_uncased_ordflokkar.bin')\n",
    "fasttext_nn = FastTextNN(model)\n",
    "\n",
    "print('Success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_adjectives = []\n",
    "\n",
    "f = open(\"lysingarord.txt\", encoding=\"utf8\")\n",
    "for x in f:\n",
    "    rm_adjective = x[:-1]\n",
    "    rm_adjectives.append(rm_adjective)\n",
    "    \n",
    "germanet_flokkar = []\n",
    "\n",
    "f = open(\"germanet_flokkar.txt\", encoding=\"utf8\")\n",
    "for x in f:\n",
    "    germanet_flokkur = x.split()\n",
    "    germanet_flokkar.append(germanet_flokkur)\n",
    "    \n",
    "yfirflokkar = []\n",
    "undirflokkar = []\n",
    "leitarord = []\n",
    "\n",
    "for i in germanet_flokkar:\n",
    "    yfirflokkar.append(i[0])\n",
    "    undirflokkar.append(i[1])\n",
    "    leitarord1 = []\n",
    "    leitarord1.append(i[2])\n",
    "    leitarord1.append(i[3])\n",
    "    leitarord.append(leitarord1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a:list, b:list):\n",
    "\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    \n",
    "    return dot_product / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbours(word:str, n:int):\n",
    "    \n",
    "    to_print = {}\n",
    "    results = fasttext_nn.nearest_words(word, n+1)\n",
    "    to_print[word] = results\n",
    "\n",
    "    #print(f'\\nThe word \"{word}\" appears {get_uniq_freq(word)} times in the training \\ndata as a uniq word but as a subword it appears {get_freq(word)}')\n",
    "    df = pd.DataFrame.from_dict(to_print)\n",
    "    pd.set_option('display.max_rows', df.shape[0]+1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anchor_compare(word:str):\n",
    "\n",
    "    target_word_vec = model.get_word_vector(word)\n",
    "    \n",
    "    similarities = []\n",
    "\n",
    "    for i in leitarord:\n",
    "\n",
    "        test_word_vec1 = model.get_word_vector(i[0])\n",
    "        test_word_vec2 = model.get_word_vector(i[1])        \n",
    "        \n",
    "        similarity1 = cosine_similarity(target_word_vec, test_word_vec1)\n",
    "        similarity2 = cosine_similarity(target_word_vec, test_word_vec2)\n",
    "\n",
    "        similarity = max(similarity1, similarity2)\n",
    "        \n",
    "        similarities.append(similarity)\n",
    "    \n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(similarities:list):\n",
    "    \n",
    "    max_similarity = max(similarities)\n",
    "    category_index = similarities.index(max_similarity)\n",
    "    \n",
    "    supercategory = yfirflokkar[category_index]\n",
    "    subcategory = undirflokkar[category_index]\n",
    "    \n",
    "    return max_similarity, supercategory, subcategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flokka(word:str):\n",
    "\n",
    "    likindi = anchor_compare(word)\n",
    "    likindi, yfirflokkur, undirflokkur = categorize(likindi)\n",
    "    \n",
    "    return likindi, yfirflokkur, undirflokkur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syna_flokkun(word, likindi, yfirflokkur, undirflokkur):\n",
    "    \n",
    "    print(\"Orð sem er er skoðað er: \", word)\n",
    "    print(\"Áætlaður yfirflokkur er: \", yfirflokkur)\n",
    "    print(\"Áætlaður undirflokkur er: \", undirflokkur)\n",
    "    print(\"Líkindi á þessari flokkun er: {:.3%}\".format(likindi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flokka_allt(words:list):\n",
    "    \n",
    "    oll_ord = []\n",
    "    \n",
    "    for word in words:\n",
    "        \n",
    "        eitt_ord = []\n",
    "        \n",
    "        likindi, yfirflokkur, undirflokkur = flokka(word)\n",
    "        \n",
    "        eitt_ord.append(word)\n",
    "        eitt_ord.append(yfirflokkur)\n",
    "        eitt_ord.append(undirflokkur)\n",
    "        eitt_ord.append(likindi)\n",
    "        \n",
    "        oll_ord.append(eitt_ord)\n",
    "        \n",
    "    return oll_ord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orð sem er er skoðað er:  glaður\n",
      "Áætlaður yfirflokkur er:  skap\n",
      "Áætlaður undirflokkur er:  tilfinning\n",
      "Líkindi á þessari flokkun er: 100.000%\n"
     ]
    }
   ],
   "source": [
    "word = 'glaður'\n",
    "\n",
    "likindi, yfirflokkur, undirflokkur = flokka(word)\n",
    "syna_flokkun(word, likindi, yfirflokkur, undirflokkur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\noll_ord = flokka_allt(rm_adjectives)\\n\\nwith open(\\'full_flokkun_lo.txt\\', \\'w\\', encoding=\\'utf8\\') as f:\\n    for word in oll_ord:\\n        for element in word:\\n            f.write(\"%s\\t\" % element)\\n        f.write(\"\\n\")\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "oll_ord = flokka_allt(rm_adjectives)\n",
    "\n",
    "with open('full_flokkun_lo.txt', 'w', encoding='utf8') as f:\n",
    "    for word in oll_ord:\n",
    "        for element in word:\n",
    "            f.write(\"%s\\t\" % element)\n",
    "        f.write(\"\\n\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Web Scrapers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
