{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "#Þessi klasi fékkst á þræðinum https://github.com/facebookresearch/fastText/pull/552\n",
    "#Þar sem Python Api bauð ekki upp á NN greiningu, þá er farinn þessi leið\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import fasttext\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from fasttext import load_model\n",
    "\n",
    "class FastTextNN:\n",
    "    \n",
    "    def __init__(self, ft_model, ft_matrix=None):\n",
    "        self.ft_model = ft_model        \n",
    "        self.ft_words = ft_model.get_words()\n",
    "        self.word_frequencies = dict(zip(*ft_model.get_words(include_freq=True)))\n",
    "        self.ft_matrix = ft_matrix\n",
    "        if self.ft_matrix is None:\n",
    "            self.ft_matrix = np.empty((len(self.ft_words), ft_model.get_dimension()))\n",
    "            for i, word in enumerate(self.ft_words):\n",
    "                self.ft_matrix[i,:] = ft_model.get_word_vector(word)\n",
    "    \n",
    "    def find_nearest_neighbor(self, query_word, vectors, n=10,  cossims=None):\n",
    "        \"\"\"\n",
    "        vectors is a 2d numpy array corresponding to the vectors you want to consider\n",
    "\n",
    "        cossims is a 1d numpy array of size len(vectors), which can be passed for efficiency\n",
    "        returns the index of the closest n matches to query within vectors and the cosine similarity (cosine the angle between the vectors)\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        query  = self.ft_model.get_word_vector(query_word)\n",
    "        if cossims is None:\n",
    "            cossims = np.matmul(vectors, query, out=cossims)\n",
    "\n",
    "        norms = np.sqrt((query**2).sum() * (vectors**2).sum(axis=1))\n",
    "        cossims = cossims/norms\n",
    "        if query_word in self.ft_words:\n",
    "            result_i = np.argpartition(-cossims, range(n+1))[1:n+1]\n",
    "        else:\n",
    "            result_i = np.argpartition(-cossims, range(n+1))[0:n]\n",
    "        return list(zip(result_i, cossims[result_i]))\n",
    "\n",
    "    def nearest_words(self, word, n=10, word_freq=None):\n",
    "        result = self.find_nearest_neighbor(word, self.ft_matrix, n=n)\n",
    "        if word_freq:\n",
    "            return [(self.ft_words[r\n",
    "            [0]], round(r[1],3)) for r in result if self.word_frequencies[self.ft_words[r[0]]] >= word_freq]\n",
    "        else:\n",
    "            return [(self.ft_words[r[0]], round(r[1],3)) for r in result]\n",
    "\n",
    "model = load_model('rm_trained_data/rmh_uncased_ordflokkar.bin')\n",
    "fasttext_nn = FastTextNN(model)\n",
    "\n",
    "print('Success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_adjectives = []\n",
    "\n",
    "f = open(\"adj_data/all_adj.txt\", encoding=\"utf8\")\n",
    "for x in f:\n",
    "    rm_adjective = x[:-1]\n",
    "    rm_adjectives.append(rm_adjective)\n",
    "\n",
    "prenoms = []    \n",
    "    \n",
    "f = open(\"adj_data/prenoms_adj.txt\", encoding=\"utf8\")\n",
    "for x in f:\n",
    "    prenom = x.split()\n",
    "    prenoms.append(prenom[:-1])\n",
    "    \n",
    "germanet_flokkar = []\n",
    "\n",
    "f = open(\"germanet_data/germanet_categories.txt\", encoding=\"utf8\")\n",
    "for x in f:\n",
    "    germanet_flokkur = x.split()\n",
    "    germanet_flokkar.append(germanet_flokkur)\n",
    "    \n",
    "yfirflokkar = []\n",
    "undirflokkar = []\n",
    "leitarord = []\n",
    "\n",
    "for i in germanet_flokkar:\n",
    "    yfirflokkar.append(i[0])\n",
    "    undirflokkar.append(i[1])\n",
    "    leitarord1 = []\n",
    "    for j in range(2,len(i)):\n",
    "        leitarord1.append(i[j])\n",
    "    leitarord.append(leitarord1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a:list, b:list):\n",
    "\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    \n",
    "    return min(dot_product / (norm_a * norm_b), 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbours(word:str, n:int):\n",
    "    \n",
    "    to_print = {}\n",
    "    results = fasttext_nn.nearest_words(word, n+1)\n",
    "    to_print[word] = results\n",
    "\n",
    "    #print(f'\\nThe word \"{word}\" appears {get_uniq_freq(word)} times in the training \\ndata as a uniq word but as a subword it appears {get_freq(word)}')\n",
    "    df = pd.DataFrame.from_dict(to_print)\n",
    "    pd.set_option('display.max_rows', df.shape[0]+1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anchor_compare(word:str):\n",
    "\n",
    "    target_word_vec = model.get_word_vector(word)\n",
    "    \n",
    "    similarities = []\n",
    "\n",
    "    for word in leitarord:\n",
    "        \n",
    "        test_word_vec = []\n",
    "        similarity = []\n",
    "        \n",
    "        for i in word:\n",
    "            \n",
    "            test_word_vec = model.get_word_vector(i)\n",
    "            similarity.append(cosine_similarity(target_word_vec, test_word_vec))\n",
    "            max_similarity = max(similarity)\n",
    "        \n",
    "        similarities.append(max_similarity)\n",
    "    \n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(similarities:list):\n",
    "    \n",
    "    max_similarity = max(similarities)\n",
    "    category_index = similarities.index(max_similarity)\n",
    "    \n",
    "    supercategory = yfirflokkar[category_index]\n",
    "    subcategory = undirflokkar[category_index]\n",
    "    \n",
    "    return max_similarity, supercategory, subcategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flokka(word:str):\n",
    "\n",
    "    likindi = anchor_compare(word)\n",
    "    likindi, yfirflokkur, undirflokkur = categorize(likindi)\n",
    "    \n",
    "    return likindi, yfirflokkur, undirflokkur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syna_flokkun(word, likindi, yfirflokkur, undirflokkur):\n",
    "    \n",
    "    print(\"Orð sem er er skoðað er: \", word)\n",
    "    print(\"Áætlaður yfirflokkur er: \", yfirflokkur)\n",
    "    print(\"Áætlaður undirflokkur er: \", undirflokkur)\n",
    "    print(\"Líkindi á þessari flokkun er: {:.3%}\".format(likindi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flokka_allt(words:list):\n",
    "    \n",
    "    oll_ord = []\n",
    "    \n",
    "    for word in words:\n",
    "        \n",
    "        eitt_ord = []\n",
    "        \n",
    "        likindi, yfirflokkur, undirflokkur = flokka(word)\n",
    "        \n",
    "        eitt_ord.append(word)\n",
    "        eitt_ord.append(yfirflokkur)\n",
    "        eitt_ord.append(undirflokkur)\n",
    "        eitt_ord.append(likindi)\n",
    "        \n",
    "        oll_ord.append(eitt_ord)\n",
    "        \n",
    "    return oll_ord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_categories(words:list):\n",
    "    \n",
    "    complete = 0\n",
    "    \n",
    "    prenom_likindir = []\n",
    "    prenom_yfirflokkar = []\n",
    "    prenom_undirflokkar = []\n",
    "    \n",
    "    for item in words:\n",
    "        \n",
    "        prenom_likindi = []\n",
    "        prenom_yfirflokkur = []\n",
    "        prenom_undirflokkur = []\n",
    "        \n",
    "        for element in item:\n",
    "            \n",
    "            likindi, yfirflokkur, undirflokkur = flokka(element)\n",
    "            prenom_likindi.append(likindi)\n",
    "            prenom_yfirflokkur.append(yfirflokkur)\n",
    "            prenom_undirflokkur.append(undirflokkur)\n",
    "            \n",
    "        prenom_likindir.append(prenom_likindi)\n",
    "        prenom_yfirflokkar.append(prenom_yfirflokkur)\n",
    "        prenom_undirflokkar.append(prenom_undirflokkur)\n",
    "        \n",
    "        complete += 1\n",
    "        \n",
    "        print(f'{complete/len(words)}\\r', end=\"\")\n",
    "    \n",
    "    return prenom_likindir, prenom_yfirflokkar, prenom_undirflokkar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orð sem er er skoðað er:  grænn\n",
      "Áætlaður yfirflokkur er:  skyn\n",
      "Áætlaður undirflokkur er:  litur\n",
      "Líkindi á þessari flokkun er: 100.000%\n"
     ]
    }
   ],
   "source": [
    "word = 'grænn'\n",
    "\n",
    "likindi, yfirflokkur, undirflokkur = flokka(word)\n",
    "syna_flokkun(word, likindi, yfirflokkur, undirflokkur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Varúð! Tekur u.þ.b. 2 klst. að keyra\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "#prenoms_likindi, prenoms_yfirflokkar, prenoms_undirflokkar = words_to_categories(prenoms)\n",
    "t1 = time.time()\n",
    "\n",
    "t1-t0\n",
    "# Muna að keyra filewrite-kóðann fyrir neðan til að geyma gögnin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-9f150eb2773b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moll_ord\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflokka_allt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrm_adjectives\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'adj_data/all_adj_categories.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moll_ord\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-ab774ad19c3f>\u001b[0m in \u001b[0;36mflokka_allt\u001b[1;34m(words)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0meitt_ord\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mlikindi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myfirflokkur\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mundirflokkur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflokka\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0meitt_ord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-5954cb11c84e>\u001b[0m in \u001b[0;36mflokka\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mflokka\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mlikindi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manchor_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mlikindi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myfirflokkur\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mundirflokkur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcategorize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlikindi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-b23f15f3c23a>\u001b[0m in \u001b[0;36manchor_compare\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mtest_word_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_word_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0msimilarity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_word_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_word_vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mmax_similarity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gup19\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\fasttext\\FastText.py\u001b[0m in \u001b[0;36mget_word_vector\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetWordVector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_sentence_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "oll_ord = flokka_allt(rm_adjectives)\n",
    "    \n",
    "with open('adj_data/all_adj_categories.txt', 'w', encoding='utf8') as f:\n",
    "    for word in oll_ord:\n",
    "        for element in word:\n",
    "            f.write(\"%s\\t\" % element)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open('adj_data/prenoms_cossims.txt', 'w', encoding='utf8') as f:\n",
    "    for word in prenoms_likindi:\n",
    "        for element in word:\n",
    "            f.write(\"%s\\t\" % element)\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "with open('adj_data/prenoms_supercategories.txt', 'w', encoding='utf8') as f:\n",
    "    for word in prenoms_yfirflokkar:\n",
    "        for element in word:\n",
    "            f.write(\"%s\\t\" % element)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open('adj_data/prenoms_subcategories.txt', 'w', encoding='utf8') as f:\n",
    "    for word in prenoms_undirflokkar:\n",
    "        for element in word:\n",
    "            f.write(\"%s\\t\" % element)\n",
    "        f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Web Scrapers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
